{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DaZone Round2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOJ1ZxsXPE4cmrLDogfnkd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomPhanAnh/Kaggle-Solution/blob/main/DaZone_Round2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpYI7_51yenR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ZALOPAY INTRODUCTION**"
      ],
      "metadata": {
        "id": "Lw4Mmwgzz27t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ZaloPay is an **E-wallet** established at the end of 2016 and is\n",
        "part of Vietnamese unicorn VNG’s digital ecosystem, which\n",
        "also includes gaming, media and cloud computing.\n",
        "\n",
        "In January 2020, ZaloPay launched on Zalo platform, with the\n",
        "aim to become the **“Vietnamese citizens’ E-wallet”.** ZaloPay\n",
        "provides daily usage in-app services such as money transfer,\n",
        "phone top-up, and paying bills. With a ready presence on local\n",
        "users’ smartphones and robust product offerings, ZaloPay has\n",
        "competitive advantages to become the champion e-wallet.\n",
        "\n",
        "In May 2022, ZaloPay reached 10M active users, which was a\n",
        "significant milestone. After a few years of traversing the\n",
        "digital payment market, we have helped to foster a cashless\n",
        "society by creating convenient payment methods for our\n",
        "consumers' daily lives."
      ],
      "metadata": {
        "id": "IgBVxjGEzyqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to Circular 23/2019/TT-NHNN, each individual must accurately fill\n",
        "out their personal information to validate their account and minimize risks\n",
        "while making a payment. Before making payments for services, e-wallets must\n",
        "be linked to the owner's bank account or debit card. As a result, ZaloPay has\n",
        "always **prioritized the growth of associated banks and studying and optimizing\n",
        "the flow of connecting banks to provide all clients with the most convenient\n",
        "wallet.**"
      ],
      "metadata": {
        "id": "u89vzg5Mz71y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Context**"
      ],
      "metadata": {
        "id": "0e-AWuFZ0HL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two systems of interest here: **front-end** and **back-end** systems. The **front-end system tracks **users’ interaction with the app (users stayed on\n",
        "which screen, clicked on which button, at which time, etc.).The back-end\n",
        "system** tracks the request in the back end that is created as a result of certain actions on the front-end. For example, when users clicked on the button “Mua ngay (buying immediately)” on an item, there’s a request on the backend at the same time and its status reflects whether users purchased successfully or not.\n",
        "\n",
        "**For the front-end dataset:** Each screen in the product flow that you will\n",
        "investigate in this assignment has its ID. The at-issues screens are numbered\n",
        "from 11 to 18, where Screen 11 is the beginning of the flow where users will fill out their bank account info and click “Lien ket ngay (link immediately)” (see the illustrative at the end of the assignment). Screens 12 to 18 reflect different meanings (e.g. the outcomes of the “Lien ket ngay” action, and our\n",
        "corresponding features for various outcomes).\n",
        "\n",
        "**For the back-end dataset:** when users click “Liên kết ngay” on screenID 11,\n",
        "a request will be recorded in the backend.csv. There are a lot of statuses here, but the one of interest is “-FACJ” status and “B”. When users encounter the “-FACJ” error, they will interact with another flow.\n",
        "\n",
        "We are testing two UIs for users who encounter “-FACJ” error. Let’s call these\n",
        "“new UI” and “old UI”. Only a subset of users can see the new UI, which includes\n",
        "screenID 12, 13, 14, 15, 16, 17, 18. The old UI does not have an associated screenID, so it temporarily assumes users that have “-FACJ” error but don’t see screenID 12 through 18 will see the old UI.\n",
        "\n",
        "The old UI and new UI are expected to help users retry and, hopefully, succeed.\n",
        "Users that finish interacting with the flow after “-FACJ” will come back to\n",
        "screenID 11 and submit another request to backend.csv. A successful request has\n",
        "a “B” status."
      ],
      "metadata": {
        "id": "5Vgcb3oz0GZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing dataset**"
      ],
      "metadata": {
        "id": "fT2xnNaUeRV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "front_end = pd.read_csv(\"Front-end dataset.csv\",delimiter = \" \")\n",
        "front_end = front_end['eventid\\tid\\tscreenid\\ttimestamp\\t\\t\\t,'].str.split(\"\\t\",expand = True)\n",
        "front_end.drop([4,5,6], axis = 1, inplace = True)\n",
        "front_end.columns = [\"eventid\",\"id\",\"screenid\",\"timestamp\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "_3LDgBJ1yi40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_comma(x):\n",
        "  if \"'\" in x:\n",
        "    return x.replace(\"'\",\" \").strip()\n",
        "  else:\n",
        "    return x\n",
        "front_end[\"id\"] = front_end[\"id\"].apply(lambda x: remove_comma(x))\n",
        "front_end[\"screenid\"] = front_end[\"screenid\"].apply(lambda x: remove_comma(x))\n",
        "front_end[\"timestamp\"] = front_end[\"timestamp\"].apply(lambda x: remove_comma(x))"
      ],
      "metadata": {
        "id": "b9q4nV78ytyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "front_end[\"timestamp\"] = pd.to_datetime(front_end[\"timestamp\"],unit = \"ms\")"
      ],
      "metadata": {
        "id": "B_YU1voLyt1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "front_end.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "fx1mh_Hcyt4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Backend Dataset**"
      ],
      "metadata": {
        "id": "gWNgCvbmyy2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "back_end = pd.read_csv(\"Back-end dataset.csv\")\n",
        "back_end = back_end['timestamp\\tstepresult\\tid'].str.split(\"\\t\",expand = True)\n",
        "back_end.rename(columns = {0:\"timestamp\",1:\"stepresult\",2:\"id\"}, inplace =True)\n",
        "back_end[\"timestamp\"] = pd.to_datetime(back_end['timestamp'], unit = 'ms')"
      ],
      "metadata": {
        "id": "oQR229vDy1xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Merging Dataset**"
      ],
      "metadata": {
        "id": "BGU9Qkbny98o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_front = front_end.groupby([\"id\",\"screenid\",\"eventid\"]).agg({\"eventid\":\"count\"}).reset_index(level = [0,1])\n",
        "max_front = count_front.groupby([\"id\",\"screenid\"]).agg({\"eventid\":\"max\"}).reset_index().sort_values([\"id\",\"screenid\"])"
      ],
      "metadata": {
        "id": "EcCz0IpDeOLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.DataFrame(max_front[\"id\"].values, columns = [\"id\"])\n",
        "dataset[\"screen11\"] = 0\n",
        "dataset[\"screen1218\"] = 0"
      ],
      "metadata": {
        "id": "LcMpetGzf2YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_front.rename(columns = {\"eventid\":\"count\"},inplace = True)\n",
        "count_front = count_front.reset_index()"
      ],
      "metadata": {
        "id": "-hzfnClUjFxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_data = count_front.merge(front_end,on = [\"eventid\",\"id\"], how = \"right\")\n",
        "merge_data[\"screenid_x\"] = merge_data[\"screenid_x\"].astype(\"int64\")"
      ],
      "metadata": {
        "id": "hwPloHSQl307"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset for screenid == 11\n",
        "merge_data11 = merge_data.loc[merge_data[\"screenid_x\"] == 11]\n",
        "new_data = pd.DataFrame(columns = merge_data.columns)\n",
        "for i in merge_data11[\"id\"].value_counts().index:\n",
        "  \n",
        "  # Test the condition to take the most interactive eventid of old UI\n",
        "  count = max(merge_data11.loc[(merge_data11[\"id\"] == i)][\"count\"])\n",
        "  eventid = merge_data11.loc[(merge_data11[\"id\"] == i ) & \n",
        "                           (merge_data11[\"count\"] == count)].sort_values([\"timestamp\",\"eventid\"])[\"eventid\"].value_counts().index[0]\n",
        "\n",
        "  # Concatenate the Data with condition\n",
        "  df = merge_data11.loc[(merge_data11[\"id\"] == i) & \n",
        "                 (merge_data11[\"eventid\"] == eventid)]  \n",
        "            \n",
        "  new_data = pd.concat([df,new_data])"
      ],
      "metadata": {
        "id": "veZAsCjXmFc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset for screenid != 11\n",
        "merge_data1218 = merge_data.loc[merge_data[\"screenid_x\"] != 11]\n",
        "new_data1218 = pd.DataFrame(columns = merge_data.columns)\n",
        "for i in merge_data1218[\"id\"].value_counts().index:\n",
        "\n",
        "  # Test the condition to take the most interactive eventid of new UI\n",
        "  count = max(merge_data1218.loc[(merge_data1218[\"id\"] == i)][\"count\"])\n",
        "  eventid = merge_data1218.loc[(merge_data1218[\"id\"] == i ) & \n",
        "                           (merge_data1218[\"count\"] == count)].sort_values([\"timestamp\",\"eventid\"])[\"eventid\"].value_counts().index[0]\n",
        "\n",
        "  # Concatenate the Data with condition\n",
        "  df = merge_data1218.loc[(merge_data1218[\"id\"] == i) & \n",
        "                 (merge_data1218[\"eventid\"] == eventid)]  \n",
        "            \n",
        "  new_data1218 = pd.concat([df,new_data1218])"
      ],
      "metadata": {
        "id": "_bempher7SIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concate to get timestamp for each loop\n",
        "data_Q1 = pd.concat([new_data,new_data1218])"
      ],
      "metadata": {
        "id": "qQ07B04XwSjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1:Prepare a report that answers the following questions**"
      ],
      "metadata": {
        "id": "ksRBXoQY0os5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is the retry rate for each UI? Does the new UI improve the retry\n",
        "rate?**"
      ],
      "metadata": {
        "id": "sIUzxHD-0o0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the retry rate for each UI? \n",
        "# 1 is new\n",
        "# 0 is old\n",
        "Q1 = data_Q1.drop_duplicates([\"id\",\"screenid_x\"])\n",
        "\n",
        "# create the dataframe to check UI old or new\n",
        "question1 = pd.DataFrame(data_Q1[\"id\"].value_counts().index, columns = [\"id\"])\n",
        "question1[\"screen11\"] = 0\n",
        "question1[\"screen1218\"] = 0"
      ],
      "metadata": {
        "id": "atcPlC9C0kKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define UI\n",
        "question1[\"UI\"] = question1.apply(lambda x: 1 if x[\"screen1218\"] > 0 else 0, axis = 1)\n",
        "question1[\"screen11\"] = question1[\"screen11\"].astype(\"int64\")\n",
        "question1[\"screen1218\"] = question1[\"screen1218\"].astype(\"int64\")\n",
        "\n",
        "# Calculate retry rate for each UI\n",
        "# In case New UI enter in screen12 to screen 18 more than log-in (screen11) => no retry rate = 0\n",
        "# Else New UI enter in screen12 to screen 18 less than log-in (screen11)    => retry rate is available\n",
        "question1[\"retry_times\"] = question1.apply(lambda x: max(0,x[\"screen11\"] - x[\"screen1218\"]), axis = 1)\n",
        "\n",
        "# retry rate of new_UI\n",
        "new_iu_retry = sum(question1.loc[question1[\"UI\"] == 1]['retry_times'])/(\n",
        "              \n",
        "                sum(question1.loc[question1[\"UI\"] == 1]['retry_times'])\n",
        "              + sum(question1.loc[question1[\"UI\"] == 1][\"screen1218\"]))\n",
        "\n",
        "# Suppose the last time of old Ui does mean they stop => the last eventid doesn't mean a retry but a stop => don't include in the number of retry\n",
        "\n",
        "# retry rate of old_UI\n",
        "old_iu_retry = (sum(question1.loc[question1[\"UI\"] == 0]['screen11']) -\n",
        "                len(question1.loc[question1[\"UI\"] == 0]['screen11']))/sum(question1.loc[question1[\"UI\"] == 0]['screen11'])"
      ],
      "metadata": {
        "id": "JflHwt_QC05Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The retry rate of New UI: {}\".format(round(new_iu_retry,2)))\n",
        "print(\"The retry rate of Old UI: {}\".format(round(old_iu_retry,2)))"
      ],
      "metadata": {
        "id": "lmcYLVDg3fbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.2: Does the new UI improve the retry rate?**"
      ],
      "metadata": {
        "id": "JYHgkz3FIQSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the hour interval for frontend dataset\n",
        "front_end[\"Year\"]  = front_end[\"timestamp\"].apply(lambda x: x.year)\n",
        "front_end[\"Month\"] = front_end[\"timestamp\"].apply(lambda x: x.month)\n",
        "front_end[\"Day\"]   = front_end[\"timestamp\"].apply(lambda x: x.day)\n",
        "front_end[\"Hour\"]  = front_end[\"timestamp\"].apply(lambda x: x.hour)\n",
        "front_end[\"timestamp2\"] = front_end.apply(lambda x: pd.datetime(x[\"Year\"],x[\"Month\"],x[\"Day\"],x[\"Hour\"]), axis = 1)"
      ],
      "metadata": {
        "id": "Z98tH_aJRB0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q12 = front_end.merge(question1[[\"id\",\"UI\"]], on = \"id\", how = \"right\")\n",
        "Q12.sort_values([\"id\",\"timestamp\"])"
      ],
      "metadata": {
        "id": "u9xoo2IBQ5K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q12.loc[(Q12[\"screenid\"] == \"11\") \n",
        "                   & (Q12[\"UI\"] == 1)].groupby(\n",
        "                  by = [\"timestamp2\"]).count().reset_index()[[\"timestamp2\",\"eventid\"]].rename(columns = {\"eventid\":\"screen11\"})"
      ],
      "metadata": {
        "id": "D866Zdrjb49R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q12_noname = pd.DataFrame(columns = Q12.columns)\n",
        "for i in Q12.loc[(Q12[\"screenid\"] != \"11\") & (Q12[\"UI\"] == 1)][\"timestamp2\"].unique():\n",
        "  df12 = Q12.loc[(Q12[\"screenid\"] != \"11\") \n",
        "                   & (Q12[\"UI\"] == 1) & (Q12[\"timestamp2\"] == i)].groupby(by = [\"timestamp2\",\"screenid\"]).count().reset_index()\n",
        "  a = max(xx.loc[(df12[\"timestamp2\"] == i)][\"eventid\"])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qPX5X56bcSOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q12.loc[(Q12[\"screenid\"] != \"11\") \n",
        "                   & (Q12[\"UI\"] == 1) & (Q12[\"timestamp2\"] == \"2021-03-15 08:00:00\")].groupby(by = [\"timestamp2\",\"screenid\"]).count().reset_index()"
      ],
      "metadata": {
        "id": "rqwFhlNhe2DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx = Q12.loc[(Q12[\"screenid\"] != \"11\") \n",
        "                   & (Q12[\"UI\"] == 1)].groupby(by = [\"timestamp2\",\"screenid\"]).count().reset_index()\n",
        "xx.head()"
      ],
      "metadata": {
        "id": "C04V1mG9SifW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(Q12.loc[(Q12[\"screenid\"] != \"11\") \n",
        "                   & (Q12[\"UI\"] == 1)].groupby(by = [\"timestamp2\",\"screenid\"]).count().reset_index()[\"eventid\"])"
      ],
      "metadata": {
        "id": "_oochLUpeIUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = max(xx.loc[(xx[\"timestamp2\"] == \"2021-03-15 08:00:00\")][\"eventid\"])\n",
        "a"
      ],
      "metadata": {
        "id": "jaUW01-UdJSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx.loc[(xx[\"timestamp2\"] == \"2021-03-15 08:00:00\") & (xx[\"eventid\"] == a)]"
      ],
      "metadata": {
        "id": "mkUTvkVmc1yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q12_timestamp = Q12_1_sc11.merge(Q12_1_sc12, on = \"timestamp2\", how = \"left\").fillna(0)\n",
        "Q12_timestamp[\"retry_times\"] = Q12_timestamp.apply(lambda x: max(0,x[\"screen11\"] - x[\"screen1218\"]), axis = 1)"
      ],
      "metadata": {
        "id": "5GloiJlmVk5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q12_timestamp[\"retry_rate\"] = Q12_timestamp.apply(lambda x: x[\"retry_times\"]/ (x[\"retry_times\"]+ x[\"screen1218\"]), axis = 1)"
      ],
      "metadata": {
        "id": "STxbV1MMVaUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (15,8))\n",
        "aa = Q12_timestamp[[\"timestamp2\",\"retry_rate\"]]\n",
        "plt.plot(aa[\"timestamp2\"],aa[\"retry_rate\"])"
      ],
      "metadata": {
        "id": "CqFUcUDHR0FX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}